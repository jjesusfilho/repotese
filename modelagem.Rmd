---
title: "Modelagem"
subtitle: "Parte II - regressão logística e modelagem preditiva com aprendizado de máquina"
author: "Livia Houaiss"
date: "1/2/2019"
output: 
 html_document:
   toc: true
   word_document:
nocite: |
  @item1, @item2
link-citations: yes
params:
  gdrive_folder_url: https://drive.google.com/drive/u/1/folders/1FroD2-OhOBqYvTH4yd6oqfDRl_O3YU1h
bibliography: biblio.bib
---

```{r init, include=FALSE}
knitr::opts_chunk$set(
  message = FALSE,
  warning = FALSE, dev = c("png", "cairo_pdf"),
  echo = TRUE,
  eval=FALSE,
  fig.retina = 2,
  fig.width = 10,
  fig.height = 6,
  fig.path = "graficos/"
)
```


```{r boilerplate-libraries, cache=FALSE, echo=FALSE,eval=TRUE}
library(gt)
library(stringi)
library(hrbrthemes)
library(googledrive)
library(tidyverse)
library(knitr)

# ensure fonts are available
extrafont::loadfonts("postscript", quiet = TRUE)
extrafont::loadfonts("pdf", quiet = TRUE)
```


## Análise inferencial e preditiva das decisões do Supremo Tribunal Federal

Na seção anterior, realizamos a análise exploratória dos dados. A análise exploratória é útil porque, para além de revelar a estrutura subjacente dos dados, permite também identificar possíveis anomalias nos dados e oferece bons "insights" sobre a relação entre a variável resposta e as variáveis preditoras, como foi possível verificar no teste do chi-quadrado e no valor da informação (IV). No entanto, essas medidas de significância e de força de associação têm alcance limitado.  Elas são basicamente importantes porque permitem corrigir inconsistências, erros de classificação, observar e ajustar anomalias (outliers, missing, skewness), selecionar as variáveis que verdadeiramente impactam o resultado e realizar o que chamamos de feature engineering, ou seja, repensar a categorização dos dados, e.g., inicialmente se manteve os órgãos colegiados (plenário, primeira turma e segunda turma) em categoria separadas, mas se notou que essas tinham efeito muito similares. Ao agrupá-las na categoria colegiadas, verificou-se que seu o poder explicativo melhorou. 

A presente seção consiste na modelagem dos dados, isto é, criar uma representação simplificada da relação entre as variáveis explicativas e a variável resposta. Seu objetivo é medir o efeito de cada variável explicativa sobre a variável resposta (i.e. decisao), isolando este efeito dos demais efeitos. A variável resposta é binária, i.e., ela assume dois valores mutuamente exclusivos "improcedente" e "procedente".

A modelagem de dados pressupõe que as observações da variável resposta estejam aleatoria e independentemente distribuídas. Outro pressuposto é o de que sua distribuição respeite uma distribuição probabilística específica, denominada distribuição de Bernoulli. Um modelo explicativo de uma determinada distribuição probabílistica é definido e caracterizado por parâmetros. Por essa razão, essas distribuições são chamadas distribuições paramétricas. Uma vez que estamos trabalhando com uma amostra das decisões, o esforço do analista é encontrar parâmetros desta distribuição amostral que se assemelhem aos parâmetros da distribuição real dos dados. A tarefa é maximizar a verossimilhança dos parâmetros encontrados a partir da modelagem na amostra em relação aos parâmetros reais da população[@hilbe2017logistic,@agresti2018introduction, @agresti2003categorical]. 

Para estimar a probabilidade de resposta favorável à reclamação, adotamos a regressão logística binária, que  é um dos procedimentos estatísticos mais utilizados em pesquisa. Ela é considerada como uma das mais importantes rotinas estatísticas em áreas como análise de cuidados de saúde, estatísticas médicas, avaliação de crédito, ecologia, estatísticas sociais e econometria[@hilbe2017logistic]. Com o aumento das pesquisas quantitativas em direito, a tendência é que ela se popularize entre os pesquisadores, vez que explicar o comportamento judicial consubstanciado nas decisões de mérito, cautelares ou liminares, constitui uma área de particular interesse do pesquisador do direito.

Há uma boa razão para essa popularidade. Ao contrário da regressão tradicional linear, ou normal, a regressão logística é apropriada para modelar uma variável binária.  Uma variável binária tem apenas dois valores - 1 e 0. Esses valores podem ser considerados como “sucesso” e “fracasso”, ou no direito, poderíamos falar em "provido" "improvido", "procedente", "improcedente", "deferido" e "indeferido", "condenado" e "absolvido", "concedido" e "denegado". Se uma pesquisadora modelar uma variável binária 1/0 em um ou mais preditores usando regressão linear, i.e. quando a variável resposta é quantitativa, e.g. salário, peso e renda, os pressupostos nas quais o modelo linear é baseado são violados. Ou seja, o modelo linear não é apropriado para modelar dados binários, somente para dados quantitativos[@hilbe2017logistic].

A regressão logística é tipicamente usada por pesquisadores e analistas em geral para três finalidades:
1. Para prever a probabilidade de que a variável resposta resposta seja igual a 1
2. Para categorizar os resultados ou previsões
3. Para acessar as probabilidades ou riscos associados aos preditores do modelo [@hilbe2017logistic]

A abordagem assumida aqui é a do realismo jurídico. Diferentemente do tecnicismo jurídico, o qual assume que o comportamento judicial irá se adequar às definições legais, o realismo jurídico toma em conta a prática judicial ou as possibilidades reais do comportamento judicial, independentemente de este se adequar ao que a lei ou a doutrina postulam como ideiais.

```{r echo=FALSE,message=FALSE,warning=FALSE}
library(tidymodels)
library(caret)
```

### Divisão da base em treino e teste

Uma vez que a base é relativamente grante, 6372 decisões, optou-se por excluir os casos com dados faltantes para a variável assunto, o que provocou um redução a 87 observações. Além disso, foram rodados não somente modelos estatísticos, mas também modelos de aprendizado de máquina (machine learning). Em poucas linhas, a diferença entre modelos estatísticos e modelos de aprendizado de máquina é que os primeiros partem do pressuposto de que os dados foram gerados respeitando uma equação matemática. No caso da regressão logística, os dados respeitam a distribuição de Bernoulli, isto é, segue a mesma lógica de valores obtidos quando lançamos uma moeda, que pode dar cara ou coroa.

Nos modelos de aprendizado de máquina não se supõe qualquer fórmula explicativa da distribuição dos dados, ao contrário, para eles entre a explicação e o resultado há uma caixa preta, o que importa é identificar padrões recorrentes nesses dados, por exemplo, quase sempre que uma decisão monocrática é agravada, verifica-se que o órgão colegiado confirma a decisão. As exceções à regra (padrão) são aos poucos incorporadas ao modelo até achar um explicação ótima[@breiman2001statistical].

Os modelos de aprendizado de máquina utilizados serão boosting[@xgboost2018] e floresta aleatória[@ranger2017]. Esses dois classificadores são aperfeiçoamentos de um outro classificador, chamado árvores de decisão. Árvores de decisão são processos de classificação das observações, no presente caso as reclamações ao STF, ordenando-as num esquema similar a uma árvore invertida, ou seja, começando do tronco, mas de cima para baixo. Cada nó da árvore representa um atributo, por exemplo, órgão julgador e segmento. Floresta aleatória utiliza processo similar, mas a partir de dezenas ou centenas de árvores, tirando-se a média delas. Boosting constrói as árvores em passos, aprendendo e utilizando-se dos erros anteriores[@jesus2017administraccao].

Para rodar os modelos, separamos as bases em duas, base treino e base teste. A base treino, com 70% das observações, contêm 4716 linhas. Como a base é desequilibrada, isto é, 2721 casos com decisões improcedentes na base treino e 1995 casos procedentes na mesma base, optamos por equilibrá-la, replicando parte dos casos de improcedência, selecionados aleatoriamente para igualá-los aos casos de improcedência.

Além disso, para melhorar o desempenho, utilizamos validação cruzada 10-fold com cinco repetições, ou seja, a base treino é dividida em 10, um desses grupos é deixado de fora, roda-se o modelo nos demais nove e verifica-se a área debaixo da curva após aplicar o resultado décima parte deixada de fora. Esse procedimento é repetido para cada uma das dez subdivisões da base treino. Volta-se a repetir todos esses processos por mais quatro vezes. Isso assegura que os melhores parâmetros e hiperparâmetros foram encontrados, aumentando assim  a acurácia do modelo explicativo.

Por fim, para rodar o modelo de regressão logística, optou-se por excluir a variável instância porque esta possui baixíssima associação com a variável resposta e poderia absorver o efeito de outras variáveis. Além disso, notou-se que as variáveis paradigma, segmento, novo_cpc e assunto, sozinhas tinham baixo poder preditivo, mas quando em interação, formam uma "nova variável" com melhor poder preditivo. 

Os modelos de machine learning são resistentes a violações dos pressupostos dos modelos lineares generalizados, de modo que não há necessidade de excluir qualquer variável do base e tampouco excluir os dados faltantes. Por outro lado, se eles além de resistentes, oferecem melhor desempenho em termos preditivos, sua capacidade explicativa é limitada. 




```{r}

rcl_dataset <- readRDS("~/projetos/livia/data/rcl_dataset.rds") %>% 
  na.omit()

#set.seed(676)
data_split <- initial_split(rcl_dataset, strata = "decisao")

rcl_train <- training(data_split)
rcl_test <- testing(data_split)

```


## Partição para machine learning

```{r }

rcl_dataset_ml <- readRDS("~/projetos/livia/data/rcl_dataset_ml.rds") %>% 
  na.omit()

#set.seed(676)
data_split <- initial_split(rcl_dataset_ml, strata = "decisao")

rcl_train_ml <- training(data_split)
rcl_test_ml <- testing(data_split)

```



```{r}
model<-dummyVars(decisao~.,data=rcl_train)

model<-predict(model,rcl_train)
model <- data.frame(model)
rcl_train <- model %>% 
mutate(decisao=!!rcl_train$decisao)
  
model<-dummyVars(decisao~.,data=rcl_test)

model<-predict(model,rcl_test)
model <- data.frame(model)
rcl_test <- model %>% 
mutate(decisao=!!rcl_test$decisao)


```



```{r}
preProcess_missingdata_model <- preProcess(rcl_train,method="knnImpute")
rcl_train <- predict(preProcess_missingdata_model,newdata=rcl_train)

preProcess_missingdata_model <- preProcess(rcl_test,method="knnImpute")
rcl_test <- predict(preProcess_missingdata_model,newdata=rcl_test)


```

### Estabele os parámetros para o trainamento e sintonização do modelo

```{r}

ctrl <- trainControl(method = "repeatedcv", # Para resampling usa validação cruzada repetica
                     number = 10, ## Número de folds a serem computados 
                     repeats = 5, ## Número de iterações
                     summaryFunction = twoClassSummary, ## Função para computar métricas de desempenho na validação cruzada
                     classProbs = TRUE, ## Computa as probabilidades das classes/etiquetas
                     savePredictions = TRUE, ## salva as predições no resampling
                     sampling="down", ## Equilibra as classes para baixo
                     allowParallel = TRUE ## autoriza paralelização.
)

```


### Regressão logística

```{r cache=FALSE,include=FALSE}
 # myGrid <- expand.grid(
 #                        alpha = 0:1,
 #                        lambda = seq(0.0001, 1, length = 20)
 #                       )
mod_GLM <- train(decisao~0+orgao_julgador+agravo+novo_cpc:paradigma:segmento:assunto,data=rcl_train_ml, method="glm",  family="binomial", trControl = ctrl,
                    tuneLength = 5, metric = "ROC")
```



```{r}
pglm<-predict(mod_GLM,rcl_test)
ppglm<-confusionMatrix(pglm,rcl_test$decisao)
ppglm

```

-->


## Resultados da regressão logística

Independentemente da regressão logística, a probabilidade geral de uma reclamação ser procedente pode ser facilmente verificada somando-se as frequências e verificando a relação de cada uma delas com o total:

```{r eval=TRUE}

readxl::read_excel("tabelas/prob_geral.xlsx")

```

Da tabela acima, verifica-se que a probabilidade de improcedência, 0,577, é superior a de procedência, 0,423. Se dividirmos um valor pelo outro, constatamos que a improcedência é 1,36 vezes mais provável que a procedência. Essa proporção não é grande, vez que em outras áreas do direito, a taxa de improcedência é muito maior. Como perdemos alguns poucos casos de improcedência ao realizar os filtros, esse número é seguramente um pouco maior.

Para efeitos de interpretação dos coeficientes, recorde-se que o **R** atribui como categoria positiva aquela que aparece em primeiro lugar na ordem alfabética. Assim, improcedente é a classe "positiva" e procedente é a "negativa". Isso significa que, ao ler os coeficientes, aqueles cujas razões de possibilidade (odds ratio - or) estão próximos de zero tendem a improceder, aqueles muitos distantes de zero tendem a dar procedência.

Como as variáveis são todas categóricas, o intercepto assume categoria base. Assim, se observarmos na tabela abaixo que reporta os estimadores, o nome do ministro Alexandre de Moraes não aparece, porque ele é a categoria de referência, ou seja, o intercepto, isto é -2.72938. Para calcular o coeficiente dos demais ministros, é necessário somá-los a este valor. Feito isso, é importante lembrar que o resultado vem em termos de log odds. Para saber quais as chances de uma reclamação ser procedente ou improcedente se for distribuída para um ministro ou outro, é necessário exponenciar esses coeficientes e dividir um pelo outro. Para dar um exemplo, se quisermos comparar o quanto muda a chance de procedência de um ministro para o outro, iremos comparar dois ministros que se encontram ordinariamente em polos distintos. Feito tal cálculo, chega-se ao seguinte resultado:

$$  e^{(3.838485 -2.72938)}/e^{-2.72938} = 46.45  $$

Uma reclamação dirigida ao Edson Fachin tem mais de 46 vezes chances de ser improcedente do que para o Alexandre de Moraes.





```{r}
tidy_glm<-tidy(mod_GLM$finalModel)
```


```{r}
readxl::read_excel("tabelas/tidy_glm.xlsx") %>% 
  knitr::kable()
```

```{r include=FALSE,cache=FALSE}
  grid_gbm <- expand.grid(interaction.depth=5, n.trees = 250,
                          shrinkage=0.1,
                          n.minobsinnode=10)

mod_GBM <- train(decisao~., data=rcl_train_ml, method="gbm", trControl = ctrl,tuneLength = 5,
                 tuneGrid=grid_gbm,
                 metric = "ROC")

```


```{r}
pgbm<-predict(mod_GBM,rcl_test_ml)
ppgbm<-confusionMatrix(pgbm,rcl_test_ml$decisao)
ppgbm
```

```{r}
p<-predict(mod_GBM,rcl_test,"prob")[[1]]
t<-ifelse(rcl_test$decisao=="improcedente",1,0)
classifierplots::roc_plot(t, p)
```

```{r}
rcl_test_ml$probabilidade<-predict(mod_GBM,rcl_test_ml,"prob")[[1]]
rcl_test_ml$t<-ifelse(rcl_test_ml$decisao=="improcedente",1,0)

a<-classifierplots::roc_plot(rcl_test_ml$t,rcl_test_ml$probabilidade)

rcl_test_ml$predito<-ifelse(rcl_test_ml$probabilidade>.4,"improcedente","procedente")

confusionMatrix(table(rcl_test_ml$predito,rcl_test_ml$decisao))


```
 
```{r}
readxl::read_excel("tabelas/matriz_confusao_boost.xlsx") %>% 
  knitr::kable()
```


```{r}

mod_xgb<-train(decisao~.,data=rcl_train_ml,method="xgbLinear",trControl=ctrl)


```
```{r}
rcl_test$probabilidade<-predict(mod_xgb,rcl_test_ml,"prob")[[1]]
rcl_test_ml$t<-ifelse(rcl_test_ml$decisao=="improcedente",1,0)

a<-classifierplots::roc_plot(rcl_test_ml$t,rcl_test_ml$probabilidade)

rcl_test_ml$predito<-ifelse(rcl_test_ml$probabilidade>.39,"improcedente","procedente")

confusionMatrix(table(rcl_test_ml$predito,rcl_test_ml$decisao))

```



```{r}
mod_rf <- train(decisao~.,data=rcl_train_ml, method = "ranger", trControl = ctrl, 
                 metric = "ROC")

prf <- predict(mod_rf,rcl_test_ml)
pprf <- confusionMatrix(prf,rcl_test_ml$decisao)
pprf
```


```{r}
rcl_test$probabilidade<-predict(mod_rf,rcl_test,"prob")[[1]]
rcl_test$t<-ifelse(rcl_test$decisao=="improcedente",1,0)

a<-classifierplots::roc_plot(rcl_test$t,rcl_test$probabilidade)

rcl_test$predito<-ifelse(rcl_test$probabilidade>.47,"improcedente","procedente")

mat_con_rf<-confusionMatrix(table(rcl_test$predito,rcl_test$decisao))

```

```{r eval=TRUE,echo=FALSE}
readxl::read_excel("tabelas/mat_con_rf.xlsx") %>% 
knitr::kable()
```


## Resultados para os modelos de aprendizado de máquina

Os resultados dos modelos floresta aleatória e boosting foram muito similares. A acurácia é mantida em 0,85, a sensitividade e a especificidade são mantidas igualmente em 0,85. Este é um excelente equilíbrio entre as resposta.  Por essa razão, iremos reportar somente os resultados para boosting. 

Diferentemente de regressão logística, não é possível apresentar coeficientes para boosting e explicar em quanto aumenta a probabilidade de concessão quando passamos de uma categoria para outra, como fizemos para regressão logística. Todavia, machine learning tem melhor poder preditivo e é possível de modo geral a importância de cada variável para o resultado. A seguir apresentamos os resultados  em forma de cenários. 

Uma vez que parte da base, 30%, ou seja, 1592 casos, foi reservada e mantida intocada para a validação do modelo, a presente subseção será utilizada para realização da análise preditiva. A análise preditiva é importante não só porque nos permite informar, para casos concretos, a probabilidade de uma decisão judicial da Suprema Corte conceder o pedido de reclamação, mas também porque é possível calcular métricas de desempenho, tais como verificar a capacidade de acerto do modelo. Igualmente, é possível verificar probabilidades ótimas para elevar a capacidade de predizer decisões favoráveis ou decisões desfaráveis, conforme o interesse em um ou em outro desfecho.


Apresentaremos quatro cenários distintos de reclamação a fim de ilustrar  tanto a capacidade preditiva do modelo quanto para mostrar como variam as chances de procedência ou improcedência a depender do perfil do caso

```{r cenario1, eval=TRUE}
readxl::read_excel("tabelas/cenario1.xlsx")
```


```{r cenario2, eval=TRUE}
readxl::read_excel("tabelas/cenario2.xlsx")
```

```{r cenario3, eval=TRUE}
readxl::read_excel("tabelas/cenario3.xlsx")
```

```{r cenario4, eval=TRUE}
readxl::read_excel("tabelas/cenario4.xlsx")
```


### Imporância das variáveis

```{r eval=TRUE,echo=FALSE}
knitr::include_graphics("graficos/importancia.png")
```



## Interpretação dos resultados

Os três modelos, regressão logística, extreme gradiente boosting e floresta aleatória são bastante similares nos resultados. Boosting e Floresta aleatória desempenham melhor em termos da acurácia, mas a regressão logística é melhor para explicar o efeito de cada uma das variáveis sobre a decisão judicial.

Os resultados mostram relevante significância estatística e prática para as órgãos julgadores e para o segmento do Judiciário. Eles sugerem que há maior chance de provimento quando as reclamações são julgadas pelos ministros Alexandre de Moraes e Gilmar Mendes. Por outro lado, ficou evidenciado que os órgãos colegiados têm papel meramente homologatório. 

Ao contrário do que comumente se esperava, o CPC 2015 não implicou em maior maior número de procedências, ao contrário, a taxa de procedência das reclamações caiu após sua vigência. Essa conclusão caminha na linha contrária do que se esperava do efeito ampliador das hipóteses de cabimento da reclamação promovido pelo CPC 2015.


```{r exemplo, echo=FALSE,message=FALSE, warning=FALSE, results="asis",caption="Exemplos de predições sobre as reclamações conforme o órgao julgador"}

set.seed(768)
(
exemplo <- rcl_test_ml %>% 
  sample_n(10)

)
```


## Métricas de desempenho

### Curva ROC

A curva ROC é um bom instrumento para verificação dos pontos de corte (thresholds) de probabilidades para respostas binárias, ou seja, os pontos de probabilidade em que teremos melhores predições de decisões favoráveis ao passo em que controlamos o número de acertos para decisões desfavoráveis. Observando os gráficos de é possível verificar do primeiro deles que em torno de 0.45, ou um pouco menos, as taxas de verdeiros positivos (tpr  ou sensitividade) passam a aumentar, chegando a algo próximo de 80%. Se reduzirmos o ponto de corte para melhorar as predições de verdadeiros positivos, teremos as taxas de falsos negativos elevadas, ou seja, erraremos muito nas predições de não provimento. O segundo gráfico é mais ilustrativo e permite identificar pontos de corte ótimos. As linhas da sensitividade e da especificidade se cruzam no ponto de corte 0,45. No entanto, se observarmos bem a linha da especificidade, notamos que entre os pontos 0,35 e 0,45 de probabilidade, seu declive é mínimo, enquanto que a linha da sensitividade mantêm-se em aclive. De modo que podemos elevar o ponto de corte para 0,43 ou 0,45 e assim melhorar os acertos para a resposta positiva, sem afetar significativamente os acertos para respostas negativas.

A curva ROC fornece uma outra métrica, a área sob a curva (area under the curve - AUC), pela qual se verifica o quão distante nosso modelo está da aleatoriedade da resposta. Ou seja, ela informa o quanto o modelo preditivo difere de uma aposta baseada no lançamento de uma moeda. Suponha uma linha diagonal saindo ponto (0,0) até o ponto (1,1) do primeiro gráfico. Esta curva teria uma área de 0.5 sob ela (o triângulo inferior à direita), indicando total aleatoriedade. Por outro lado, uma linha que saísse do ponto (0,0), passando pelo ponto (0,1) e terminasse no ponto (1,1), teria uma área de 1 (área de todo o quadrante), indicando 100% de acerto. A curva do gráfico, como mostra o valor anotado no interior do gráfico, está sobre uma área de mais de .93, o que indica um desempenho excelente do modelo. Isto é,  está longe da aleatoridade.


```{r plot-roc, echo=TRUE, message=FALSE, warning=FALSE,fig.cap="Curvas roc, sensitividade e especificidade"}

curva_roc<- AUC::roc(as.factor(rcl_test_ml$predito),rcl_test_ml$decisao)

gg_curva_roc <- curva_roc %>% 
ggplot(aes(1-d,b,color=a))+
  geom_path()+
  scale_x_continuous(breaks=seq(0,1,.10))+
  annotate(geom="text",x = .75,y=.50,label=paste0("AUC:", 92))+
  labs(x="taxa de falsos positivos",y="taxa de verdadeiros positivos",title="Curva ROC")+
  theme_minimal()+
  guides(fill="none",color="none")


## O primeiro nível é "não" e ele termina por ser medido como "sensitividade", por essa razão, eu inverti as etiquetas.
curva_roc %>% 
  gather(metrica,taxa,-a) %>% 
  ggplot(aes(a,taxa,color=metrica))+
     geom_line()+
    scale_color_discrete(name="Ponto de corte",labels=c("Sensitividade","Especificidade"))+
    scale_x_continuous(breaks=seq(0,1,.10))+
    labs(x="métricas",y="taxa de verdadeiros (positivos e negativos)",title="Curvas de sensitividade e especificidade")+

  theme_minimal()
  
gridExtra::grid.arrange(p1, p2, newpage = TRUE, layout_matrix = matrix(1:2))
  
```

```{r eval=TRUE,echo=FALSE}
knitr::include_graphics("graficos/gg_curva_roc.png")
```


Tomando a visualização da curva roc em consideração, abaixo mostramos as métricas de desempenho do modelo na base teste. A acuracia alcançou 85%, sendo que a sensitividade, ou seja, taxa de provimentos corretamente preditos, foi de 85%. Já a especificidade, taxa de improvimentos corretamente preditos, alcançou 85%. Fixamos o ponto de corte em 0,4, isto é, novos casos serão classificados como providos quando a probabilidade de provimento estiver acima de 0,4.



```{r matriz-confusao, echo=FALSE, message=FALSE, warning=FALSE}

test_set$predicted_values<-ifelse(test_set$pred>.43,"sim","não") 

table(test_set$predicted_values,test_set$decisao) %>%
  caret::confusionMatrix()

```

```{r eval=TRUE, echo=FALSE}
readxl::read_excel("tabelas/matriz_confusao_boost.xlsx") %>% 
  kable()
```


## Conclusão

1- O CPC/15 não elevou a taxa de provimento, ao contrário, após sua vigência as taxas de provimento  cairam.
2 - Nao se pode afirmar que há um descumprimento sistemeatico das cortes inferiores, no entanto a justiça do trabalho é consistentemente recalcitrante. 

3- A figura do ministro é crucial. As chances de procedência entre um ministo e outro se alteram significativametne.


A pesquisa buscou verificar duas hipóteses:

1. Se há descumprimento sistemático das decisões da Suprema Corte por parte das cortes inferiores.

2. Se o advento do CPC 2015 resultou na redução do descumprimento.

Quanto à primeira hipótese, os dados não revelam um descumprimento sistemático das decisões do STF por parte do STJ, da Justiça Eleitoral, da Justiça Federal e da Justiça Estadual. No entanto, a Justiça do Trabalho foi aquela que mais sofreu reclamações. Mais da metade das reclamações tiveram como reclamada a Justiça do Trabalho. Os resultados mostraram significância estatística para a Justiça do Trabalho.

# Referências



```{r procedimentos, eval=TRUE, echo = FALSE, message = FALSE, warning = FALSE}
googledrive::drive_auth()

# locate the folder
gdrive_prod_folder <- googledrive::as_id(params$gdrive_folder_url)

# clean it out
gdrls <- googledrive::drive_ls(gdrive_prod_folder)
if (nrow(gdrls) > 0) {
  dplyr::pull(gdrls, id) %>%
    purrr::walk(~googledrive::drive_rm(googledrive::as_id(.x)))
}

# upload new
list.files(here::here(),"modelagem", recursive = TRUE, full.names = TRUE) %>%
  purrr::walk(googledrive::drive_upload, path = gdrive_prod_folder)
```


